{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "132cb48b-c8be-4cd4-8c3d-dc680d31d46c",
   "metadata": {},
   "source": [
    "# Experiment 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c665fbc-c7d9-4fdb-905b-83332b1a528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Dependencies\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdcaddaa-f123-4728-a4e3-dba3cf7ea497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original working directory is /Users/jankreischer/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code/experiments/experiment02\n"
     ]
    }
   ],
   "source": [
    "original_working_directory_path = os.getcwd()\n",
    "print(\"The original working directory is {0}\".format(os.getcwd()))\n",
    "\n",
    "def to_original_working_directory():\n",
    "    os.chdir(original_working_directory_path)\n",
    "    print(f\"Changed to original working directory {original_working_directory_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a8daa98-5dcc-4246-830d-350e32071292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_root_working_directory():\n",
    "    root_working_directory_path = os.path.join(original_working_directory_path, \"../..\")\n",
    "    os.chdir(root_working_directory_path)\n",
    "    print(f\"Changed to root working directory {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34f6bcdb-d0fe-4aaa-9520-50370ebaac7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to root working directory /Users/jankreischer/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code\n"
     ]
    }
   ],
   "source": [
    "to_root_working_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b13ebd8b-d3bc-484d-aed4-070cccf7f7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Dependencies\n",
    "from experiments.experiment_02.environment import SensorEnvironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd081675-37e7-4315-af84-3ad33d1281a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Dependencies\n",
    "from src.data_provider import DataProvider\n",
    "from src.agent import Agent\n",
    "from src.custom_types import Behavior\n",
    "from src.simulation_engine import SimulationEngine\n",
    "from src.evaluation_utils import plot_learning, seed_random, get_pretrained_agent, evaluate_agent, \\\n",
    "    evaluate_agent_on_afterstates\n",
    "from src.autoencoder_utils import evaluate_ae_on_no_mtd_behavior, get_pretrained_ae, pretrain_ae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40449525-d931-4b79-9284-7f4ef66c129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the parent directory to the list of directories\n",
    "# that the interpreter will search for dependencies \n",
    "#module_path = os.path.abspath(os.path.join('../../src'))\n",
    "#if module_path not in sys.path:\n",
    "#    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed661947-a551-45e6-8aa6-c6ffef53036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "GAMMA = 0.1\n",
    "BATCH_SIZE = 100\n",
    "BUFFER_SIZE = 500\n",
    "MIN_REPLAY_SIZE = 100\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_DEC = 1e-4\n",
    "EPSILON_END = 0.01\n",
    "TARGET_UPDATE_FREQ = 100\n",
    "LEARNING_RATE = 1e-4\n",
    "N_EPISODES = 10000\n",
    "LOG_FREQ = 100\n",
    "DIMS = 20\n",
    "PI = 3\n",
    "SAMPLES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b76f920-3834-4d0c-ba22-0319998dbefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jankreischer/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code\n",
      "size train: (5375, 46), size valid: (1344, 46)\n",
      "---Training AE---\n",
      "AE threshold: 0.4145037497588934\n",
      "save model to: experiments/experiment_02/trained_models/ae_model_pi3.pth\n",
      "ae_interpreter threshold: 0.4145037497588934\n",
      "\\begin{tabular}{ll}\n",
      "\\hline\n",
      " Behavior           & Accuracy   \\\\\n",
      "\\hline\n",
      " normal             & 84.86\\%     \\\\\n",
      " ransomware\\_poc     & 100.00\\%    \\\\\n",
      " bdvl               & 100.00\\%    \\\\\n",
      " beurk              & 12.16\\%     \\\\\n",
      " the\\_tick           & 31.56\\%     \\\\\n",
      " backdoor\\_jakoritar & 11.22\\%     \\\\\n",
      " data\\_leak\\_1        & 95.40\\%     \\\\\n",
      " data\\_leak\\_2        & 100.00\\%    \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "episode  0 | episode_return 1.00 | average episode_return 1.00 | epsilon 1.00\n",
      "episode  1 | episode_return -0.33 | average episode_return 0.33 | epsilon 1.00\n",
      "episode  2 | episode_return 1.00 | average episode_return 0.56 | epsilon 1.00\n",
      "episode  3 | episode_return -0.33 | average episode_return 0.33 | epsilon 1.00\n",
      "episode  4 | episode_return -0.33 | average episode_return 0.20 | epsilon 1.00\n",
      "episode  5 | episode_return 1.00 | average episode_return 0.33 | epsilon 1.00\n",
      "episode  6 | episode_return -0.50 | average episode_return 0.21 | epsilon 1.00\n",
      "episode  7 | episode_return 1.00 | average episode_return 0.31 | epsilon 1.00\n",
      "episode  8 | episode_return 1.00 | average episode_return 0.39 | epsilon 1.00\n",
      "episode  9 | episode_return 0.00 | average episode_return 0.35 | epsilon 1.00\n",
      "episode  10 | episode_return -0.50 | average episode_return 0.20 | epsilon 1.00\n",
      "episode  11 | episode_return 1.00 | average episode_return 0.33 | epsilon 1.00\n",
      "episode  12 | episode_return 0.00 | average episode_return 0.23 | epsilon 1.00\n",
      "episode  13 | episode_return -0.33 | average episode_return 0.23 | epsilon 1.00\n",
      "episode  14 | episode_return 1.00 | average episode_return 0.37 | epsilon 1.00\n",
      "episode  15 | episode_return -0.50 | average episode_return 0.22 | epsilon 1.00\n",
      "episode  16 | episode_return 1.00 | average episode_return 0.37 | epsilon 1.00\n",
      "episode  17 | episode_return -0.33 | average episode_return 0.23 | epsilon 1.00\n",
      "episode  18 | episode_return 0.00 | average episode_return 0.13 | epsilon 1.00\n",
      "episode  19 | episode_return 1.00 | average episode_return 0.23 | epsilon 1.00\n",
      "episode  20 | episode_return -0.50 | average episode_return 0.23 | epsilon 1.00\n",
      "episode  21 | episode_return 0.00 | average episode_return 0.13 | epsilon 1.00\n",
      "episode  22 | episode_return 1.00 | average episode_return 0.23 | epsilon 1.00\n",
      "episode  23 | episode_return 0.00 | average episode_return 0.27 | epsilon 0.99\n",
      "episode  24 | episode_return 1.00 | average episode_return 0.27 | epsilon 0.99\n",
      "episode  25 | episode_return -0.33 | average episode_return 0.28 | epsilon 0.99\n",
      "episode  26 | episode_return 1.00 | average episode_return 0.28 | epsilon 0.99\n",
      "episode  27 | episode_return 0.00 | average episode_return 0.32 | epsilon 0.99\n",
      "episode  28 | episode_return 0.00 | average episode_return 0.32 | epsilon 0.99\n",
      "episode  29 | episode_return -0.50 | average episode_return 0.17 | epsilon 0.99\n",
      "episode  30 | episode_return 1.00 | average episode_return 0.32 | epsilon 0.99\n",
      "episode  31 | episode_return 0.00 | average episode_return 0.32 | epsilon 0.99\n",
      "episode  32 | episode_return -0.50 | average episode_return 0.17 | epsilon 0.99\n",
      "episode  33 | episode_return 1.00 | average episode_return 0.27 | epsilon 0.99\n",
      "episode  34 | episode_return 0.00 | average episode_return 0.17 | epsilon 0.99\n",
      "episode  35 | episode_return 0.00 | average episode_return 0.20 | epsilon 0.99\n",
      "episode  36 | episode_return -0.50 | average episode_return 0.05 | epsilon 0.99\n",
      "episode  37 | episode_return 0.00 | average episode_return 0.05 | epsilon 0.99\n",
      "episode  38 | episode_return 1.00 | average episode_return 0.15 | epsilon 0.99\n",
      "episode  39 | episode_return 1.00 | average episode_return 0.30 | epsilon 0.99\n",
      "episode  40 | episode_return -0.33 | average episode_return 0.17 | epsilon 0.99\n",
      "episode  41 | episode_return 0.00 | average episode_return 0.17 | epsilon 0.99\n",
      "episode  42 | episode_return 0.00 | average episode_return 0.22 | epsilon 0.99\n",
      "episode  43 | episode_return 1.00 | average episode_return 0.22 | epsilon 0.99\n",
      "episode  44 | episode_return 0.00 | average episode_return 0.22 | epsilon 0.99\n",
      "episode  45 | episode_return 0.00 | average episode_return 0.22 | epsilon 0.99\n",
      "episode  46 | episode_return 0.00 | average episode_return 0.27 | epsilon 0.99\n",
      "episode  47 | episode_return 0.00 | average episode_return 0.27 | epsilon 0.99\n",
      "episode  48 | episode_return -0.50 | average episode_return 0.12 | epsilon 0.99\n",
      "episode  49 | episode_return -0.50 | average episode_return -0.03 | epsilon 0.99\n",
      "episode  50 | episode_return 0.00 | average episode_return 0.00 | epsilon 0.99\n",
      "episode  51 | episode_return 0.00 | average episode_return 0.00 | epsilon 0.99\n",
      "episode  52 | episode_return -0.33 | average episode_return -0.03 | epsilon 0.99\n",
      "episode  53 | episode_return 0.00 | average episode_return -0.13 | epsilon 0.99\n",
      "episode  54 | episode_return -0.33 | average episode_return -0.17 | epsilon 0.99\n",
      "episode  55 | episode_return 0.00 | average episode_return -0.17 | epsilon 0.99\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m SimulationEngine\u001b[38;5;241m.\u001b[39minit_replay_memory(agent\u001b[38;5;241m=\u001b[39magent, env\u001b[38;5;241m=\u001b[39menv, min_size\u001b[38;5;241m=\u001b[39mMIN_REPLAY_SIZE)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# main training\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m episode_returns, eps_history \u001b[38;5;241m=\u001b[39m \u001b[43mSimulationEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_agent_offline\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPISODES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                                                                    \u001b[49m\u001b[43mt_update_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTARGET_UPDATE_FREQ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m end \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal training time: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code/src/simulation_engine.py:64\u001b[0m, in \u001b[0;36mSimulationEngine.learn_agent_offline\u001b[0;34m(agent, env, num_episodes, t_update_freq)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m     62\u001b[0m     agent\u001b[38;5;241m.\u001b[39mepisode_action_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m---> 64\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m obs \u001b[38;5;241m=\u001b[39m new_obs\n\u001b[1;32m     67\u001b[0m episode_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code/src/agent.py:108\u001b[0m, in \u001b[0;36mAgent.learn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39monline_net\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    107\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monline_net\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# epsilon decay\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps_dec \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps_min \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps_min\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.9/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.9/site-packages/torch/optim/optimizer.py:23\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.9/site-packages/torch/optim/adam.py:234\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`requires_grad` is not supported for `step` in differentiable mode\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    232\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 234\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m         \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.9/site-packages/torch/optim/adam.py:300\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 300\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.9/site-packages/torch/optim/adam.py:363\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    360\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[43mexp_avg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    364\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment_base_dir = \"experiments/experiment_02\"\n",
    "\n",
    "seed_random()\n",
    "start = time()\n",
    "\n",
    "# read in all preprocessed data for a simulated, supervised environment to sample from\n",
    "# train_data, test_data = DataProvider.get_reduced_dimensions_with_pca(DIMS, pi=PI)\n",
    "train_data, test_data, scaler = DataProvider.get_scaled_train_test_split(pi=PI, scaling_minmax=True,\n",
    "                                                                         scale_normal_only=True)\n",
    "# get splits for RL & AD of normal data\n",
    "n = 100\n",
    "s = 0.3\n",
    "b = Behavior.NORMAL\n",
    "normal_data = train_data[b]\n",
    "l = len(normal_data)\n",
    "train_data[b] = normal_data[:int(l * s)]  # use fixed number of samples for Reinforcement Agent training\n",
    "# COMMENT/UNCOMMENT BELOW for pretraining of autoencoder\n",
    "ae_path = f\"{experiment_base_dir}/trained_models/ae_model_pi3.pth\"\n",
    "ae_data = normal_data[int(l * s):]  # use remaining samples for autoencoder\n",
    "train_ae_x, valid_ae_x = pretrain_ae_model(ae_data=ae_data, path=ae_path, split=0.8, lr=1e-4, momentum=0.9,\n",
    "                                           num_epochs=100, num_std=2.5)\n",
    "dims = len(train_ae_x[0, :])\n",
    "# AE evaluation of pretrained model\n",
    "ae_interpreter = get_pretrained_ae(path=ae_path, dims=dims)\n",
    "# AE can directly be tested on the data that will be used for RL: pass train_data to testing\n",
    "evaluate_ae_on_no_mtd_behavior(ae_interpreter=ae_interpreter, test_data=train_data)\n",
    "\n",
    "# Reinforcement Learning\n",
    "env = SensorEnvironment(train_data, interpreter=ae_interpreter, state_samples=SAMPLES)\n",
    "\n",
    "agent = Agent(input_dims=env.observation_space_size, n_actions=len(env.actions), buffer_size=BUFFER_SIZE,\n",
    "              batch_size=BATCH_SIZE, lr=LEARNING_RATE, gamma=GAMMA, epsilon=EPSILON_START, eps_end=EPSILON_END)\n",
    "\n",
    "# initialize memory replay buffer (randomly)\n",
    "SimulationEngine.init_replay_memory(agent=agent, env=env, min_size=MIN_REPLAY_SIZE)\n",
    "\n",
    "# main training\n",
    "episode_returns, eps_history = SimulationEngine.learn_agent_offline(agent=agent, env=env, num_episodes=N_EPISODES,\n",
    "                                                                    t_update_freq=TARGET_UPDATE_FREQ)\n",
    "\n",
    "end = time()\n",
    "print(\"Total training time: \", end - start)\n",
    "\n",
    "num = 0\n",
    "agent.save_agent_state(num, experiment_base_dir)\n",
    "\n",
    "x = [i + 1 for i in range(N_EPISODES)]\n",
    "filename = f\"{experiment_base_dir}/mtd_agent_p2_{SAMPLES}_sample.pdf\"\n",
    "plot_learning(x, episode_returns, eps_history, filename)\n",
    "\n",
    "# check predictions with dqn from trained and stored agent\n",
    "pretrained_agent = get_pretrained_agent(path=f\"{experiment_base_dir}/trained_models/agent_{num}.pth\",\n",
    "                                        input_dims=env.observation_space_size, n_actions=len(env.actions),\n",
    "                                        buffer_size=BUFFER_SIZE)\n",
    "\n",
    "evaluate_agent(pretrained_agent, test_data=test_data)\n",
    "\n",
    "# print(\"evaluate p2 agent on 'real' decision and afterstate data:\")\n",
    "# dtrain, dtest, atrain, atest = DataProvider.get_reduced_dimensions_with_pca_ds_as(dims,\n",
    "#                                                                                   dir=\"offline_prototype_2_raw_behaviors/\")\n",
    "# evaluate_agent(agent=pretrained_agent, test_data=dtest)\n",
    "# evaluate_agent_on_afterstates(agent=pretrained_agent, test_data=atest)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FedRL-for-IT-Sec",
   "language": "python",
   "name": "fedrl-for-it-sec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
