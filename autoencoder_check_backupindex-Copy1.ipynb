{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba26052c-2bb9-48c9-9565-ed139cc65688",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Investigating the State Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb2b2e7b-5fad-4d40-b163-163fc1e4eb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jankreischer/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f95e578-2a3c-48a4-874d-e1f93ff2961a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Behavior(Enum):\n",
    "    NORMAL = \"normal\"\n",
    "    ROOTKIT_BDVL = \"bdvl\"\n",
    "    ROOTKIT_BEURK = \"beurk\"\n",
    "    CNC_BACKDOOR_JAKORITAR = \"backdoor_jakoritar\"\n",
    "    CNC_THETICK = \"the_tick\"\n",
    "    CNC_OPT1 = \"data_leak_1\"\n",
    "    CNC_OPT2 = \"data_leak_2\"\n",
    "    RANSOMWARE_POC = \"ransomware_poc\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a60cb02-c4ed-45b7-9a84-e140425f714f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset-01.csv')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39e0b3bc-16b4-4bd8-86ec-49769d526c42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full length of dataset: 59004\n"
     ]
    }
   ],
   "source": [
    "print(f\"Full length of dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36487322-41b1-458a-886b-c7c4e93f3212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping time status features\n",
    "time_status_columns = ['time', 'timestamp', 'seconds']\n",
    "try:\n",
    "    dataset.drop(time_status_columns, inplace=True, axis=1)\n",
    "except:\n",
    "    print(f\"All time status features {(time_status_columns)} are removed from the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1538a690-6a0c-4c03-b3b0-022f61c25f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fast_ml.feature_selection import get_constant_features\n",
    "\n",
    "# Removing constant features\n",
    "constant_features = set(get_constant_features(dataset, threshold=0.99, dropna=False)['Var'])\n",
    "try:\n",
    "    dataset.drop(constant_features, inplace=True, axis=1)\n",
    "except:\n",
    "    print(f\"All constant features {(constant_features)} are removed from the dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a35a64e8-ef80-4cec-b47e-a3ea592270b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Scaling\n",
    "fit_normal_behavior_only = True\n",
    "standard_scaling = False\n",
    "if standard_scaling:\n",
    "    scaler = StandardScaler()\n",
    "else:\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "print(f\"Using {scaler}\")\n",
    "\n",
    "if fit_normal_behavior_only: \n",
    "    scaler.fit(dataset[dataset['behavior'] == \"Behavior.NORMAL\"].values[:,:-1])\n",
    "else: \n",
    "    scaler.fit(dataset.values[:,:-1])\n",
    "\n",
    "scaled_dataset = pd.DataFrame(scaler.transform(dataset.values[:,:-1]), columns=dataset.columns.drop(\"behavior\"), index=dataset.index)\n",
    "scaled_dataset[\"behavior\"] = dataset[\"behavior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a90a50c0-f0b0-4a60-bcc2-5fa14b640459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14702, 85)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_normal = scaled_dataset.loc[scaled_dataset['behavior'] == \"Behavior.NORMAL\"].drop([\"behavior\"],  axis=1).to_numpy()\n",
    "X_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d55da84b-ac0a-4cea-89ed-9f2b81446e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss\n",
    "\n",
    "class AutoEncoder(torch.nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, n_features):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "        nn.Linear(n_features, 64),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(64, 20),\n",
    "        nn.GELU(),\n",
    "        #nn.Linear(32, 16),\n",
    "        #nn.GELU(),\n",
    "        #nn.Linear(16, 32),\n",
    "        #nn.GELU(),\n",
    "        nn.Linear(20, 64),\n",
    "        nn.BatchNorm1d(64),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(64, n_features),\n",
    "        nn.GELU()\n",
    "    )\n",
    "        print(\"Usring 20\")\n",
    "        self.threshold = None\n",
    "        self.loss_mean = None\n",
    "        self.loss_standard_deviation = None\n",
    "        self.prediction_loss_function = torch.nn.MSELoss(reduction=\"sum\")\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    \n",
    "    def pretrain(self, X_normal, optimizer=torch.optim.SGD, loss_function=torch.nn.MSELoss(reduction='mean'), num_epochs: int = 15, batch_size=64, verbose=False):\n",
    "        threshold = int(0.5*len(X_normal))\n",
    "        X_train = X_normal[:threshold]\n",
    "        X_valid = X_normal[threshold:]\n",
    "        \n",
    "        training_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(X_train).type(torch.float),\n",
    "        )\n",
    "        training_data_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "        epoch_losses = []\n",
    "        #for e in tqdm(range(num_epochs), unit=\"epoch\", leave=False):\n",
    "        for e in range(num_epochs):\n",
    "            self.train()\n",
    "            current_losses = []\n",
    "            for batch_index, (inputs,) in enumerate(training_data_loader):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = loss_function(inputs, outputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                current_losses.append(loss.item())\n",
    "            \n",
    "            epoch_losses.append(np.average(current_losses))\n",
    "            if verbose:\n",
    "                print(f'Training Loss in epoch {e + 1}: {epoch_losses[e]}')\n",
    "            \n",
    "        self.analyze_loss(X_valid)\n",
    "\n",
    "    '''\n",
    "    This function uses normal data samles \n",
    "    after training the autoencoder to determine\n",
    "    values that can be considered normal\n",
    "    for the reconstruction loss based on normal samples\n",
    "    '''\n",
    "    def analyze_loss(self, X_valid):\n",
    "        validation_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(X_valid).type(torch.float),\n",
    "\n",
    "        )\n",
    "        validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=True, drop_last=True)\n",
    "        \n",
    "        losses = []\n",
    "        \n",
    "        self.eval() \n",
    "        with torch.no_grad():\n",
    "            for batch_index, (inputs,) in enumerate(validation_data_loader):\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = self.prediction_loss_function(inputs, outputs)\n",
    "                losses.append(loss.item())\n",
    "        \n",
    "        losses = np.array(losses)\n",
    "        print(f\"len(losses): {len(losses)}\")\n",
    "        self.loss_mean = losses.mean()\n",
    "        self.loss_standard_deviation = losses.std()\n",
    "        print(f\"loss_mean: {self.loss_mean}\")\n",
    "        print(f\"loss_standard_deviation: {self.loss_standard_deviation}\")\n",
    "\n",
    "        \n",
    "    def predict(self, x, n_std=3):\n",
    "        test_data = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(x).type(torch.float32)\n",
    "        )\n",
    "        test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "        all_predictions = torch.tensor([])  # .cuda()\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for idx, (batch_x,) in enumerate(test_data_loader):\n",
    "                model_predictions = self.forward(batch_x)\n",
    "                model_predictions = self.prediction_loss_function(model_predictions, batch_x).unsqueeze(0)  # unsqueeze as batch_size set to 1\n",
    "                all_predictions = torch.cat((all_predictions, model_predictions))\n",
    "\n",
    "        threshold = self.loss_mean + n_std * self.loss_standard_deviation\n",
    "        all_predictions = (all_predictions > threshold).type(torch.long)\n",
    "        return all_predictions.flatten()\n",
    "    \n",
    "    \n",
    "    def predict_deviation(self, x):\n",
    "        test_data = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(x).type(torch.float32)\n",
    "        )\n",
    "        test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "        prediction_errors = torch.tensor([])\n",
    "        \n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_index, (inputs,) in enumerate(test_data_loader):\n",
    "                prediction = self.forward(inputs)\n",
    "                prediction_error = self.prediction_loss_function(inputs, prediction).unsqueeze(0)  # unsqueeze as batch_size set to 1\n",
    "                prediction_errors = torch.cat((prediction_errors, prediction_error))\n",
    "\n",
    "        return prediction_errors\n",
    "    \n",
    "    \n",
    "    def score(self):\n",
    "        n_std, accuracy = self.accuracy_score(None, None)\n",
    "        if self.verbose:\n",
    "            print(f\"Highest validation accuracy achieved {accuracy:.2f} with n_std={n_std}\")\n",
    "            self.evaluate(n_std)\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def accuracy_score(self, X, y):\n",
    "        #if not self.threshold:\n",
    "        #loss_mean, loss_standard_deviation = self.analyze_loss(X)\n",
    "        #n_stds = np.arange(0.1, 3, 0.1)\n",
    "        if self.loss_mean == None or self.loss_standard_deviation == None:\n",
    "              #print(\"accuracy_score_optimized > accurcy_loss()\")\n",
    "              self.analyze_loss()\n",
    "    \n",
    "        best_accuracy = 0\n",
    "        best_n_std = 0\n",
    "        #accuracies = []\n",
    "        y_dev = self.predict_deviation((self.X_test).astype(np.float32))\n",
    "        for n_std in self.n_stds:\n",
    "            y_true = self.y_test\n",
    "            threshold = self.loss_mean + n_std * self.loss_standard_deviation\n",
    "            y_pred = (y_dev > threshold).type(torch.long).detach().cpu().numpy()\n",
    "            \n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_n_std = n_std\n",
    "            #if self.verbose:\n",
    "            #    print(f\"n_std {n_std:.2f} -> accuracy: {accuracy}\")\n",
    "\n",
    "        return best_n_std, best_accuracy\n",
    "    \n",
    "    \n",
    "    def evaluate(self, evaluation_data, n_std=3, tablefmt='pipe'):\n",
    "        results = []\n",
    "        labels= [0,1]\n",
    "        pos_label = 1\n",
    "        \n",
    "        y_true_total = np.empty([0])\n",
    "        y_pred_total = np.empty([0])\n",
    "        for behavior in Behavior:\n",
    "            X_behavior = evaluation_data.loc[evaluation_data['behavior'] == f\"Behavior.{behavior.name}\"].drop([\"behavior\"],  axis=1).to_numpy()\n",
    "            print(len(X_behavior))\n",
    "            y_true = np.array([0 if behavior == Behavior.NORMAL else 1] * len(X_behavior)).astype(int)\n",
    "            y_true_total = np.concatenate((y_true_total, y_true))\n",
    "            \n",
    "            print(f\"Using n_std: {n_std} as prediction threshold\")\n",
    "            y_pred = self.predict(X_behavior.astype(np.float32), n_std=n_std)\n",
    "            y_pred_total = np.concatenate((y_pred_total, y_pred))\n",
    "\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "            n_samples = len(y_true)\n",
    "            results.append([behavior.name.replace(\"_\", \"\\_\"), f'{(100 * accuracy):.2f}\\%', '\\\\notCalculated', '\\\\notCalculated', '\\\\notCalculated', str(n_samples)])\n",
    "\n",
    "        accuracy = accuracy_score(y_true_total, y_pred_total)\n",
    "        precision = precision_score(y_true_total, y_pred_total, average='binary', labels=labels, pos_label=pos_label, zero_division=1)\n",
    "        recall = recall_score(y_true_total, y_pred_total, average='binary', labels=labels, pos_label=pos_label, zero_division=1)\n",
    "        f1 = f1_score(y_true_total, y_pred_total, average='binary', labels=labels, pos_label=pos_label, zero_division=1)\n",
    "        n_samples = len(y_true_total)\n",
    "        results.append([\"GLOBAL\", f'{(100 * accuracy):.2f}\\%', f'{(100 * precision):.2f}\\%', f'{(100 * recall):.2f}\\%', f'{(100 * f1):.2f}\\%', n_samples])\n",
    "        print(\"-----------\")\n",
    "        print(tabulate(results, headers=[\"Behavior\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"\\#Samples\"], tablefmt=tablefmt)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1e07e2fb-92fd-4bfa-9ac4-02b270504a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usring 20\n"
     ]
    }
   ],
   "source": [
    "N_FEATURES = X_normal.shape[1]\n",
    "autoencoder = AutoEncoder(N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e35819ae-249c-40ed-812e-84a42e8c4ca6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(losses): 7351\n",
      "loss_mean: 0.28526486205997525\n",
      "loss_standard_deviation: 0.2960638965343553\n"
     ]
    }
   ],
   "source": [
    "autoencoder.pretrain(X_normal, optimizer=torch.optim.Adam(autoencoder.parameters(), lr=1e-4,  weight_decay=0.01), loss_function=RMSELoss(), num_epochs=100, batch_size=64, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f6774653-b07f-4100-85b9-979833cc5f99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.7 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 93.65\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 98.42\\%    & 97.94\\%        & 100.00\\%       & 98.96\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# With batch norm and GELU and 64 x 20 nodes\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.7, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bb9468db-cac1-47c0-9e0a-68bc099c9dab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.75 as prediction threshold\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [144]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# With batch norm and GELU and 64 x 16 nodes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m evaluation_data \u001b[38;5;241m=\u001b[39m scaled_dataset\n\u001b[0;32m----> 3\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtablefmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlatex_raw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36mAutoEncoder.evaluate\u001b[0;34m(self, evaluation_data, n_std, tablefmt)\u001b[0m\n\u001b[1;32m    189\u001b[0m y_true_total \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((y_true_total, y_true))\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing n_std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_std\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as prediction threshold\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 192\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_behavior\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_std\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m y_pred_total \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((y_pred_total, y_pred))\n\u001b[1;32m    195\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_true, y_pred)\n",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36mAutoEncoder.predict\u001b[0;34m(self, x, n_std)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (batch_x,) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_data_loader):\n\u001b[0;32m--> 116\u001b[0m         model_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m         model_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loss_function(model_predictions, batch_x)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# unsqueeze as batch_size set to 1\u001b[39;00m\n\u001b[1;32m    118\u001b[0m         all_predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((all_predictions, model_predictions))\n",
      "Input \u001b[0;32mIn [136]\u001b[0m, in \u001b[0;36mAutoEncoder.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# With batch norm and GELU and 64 x 16 nodes\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.75, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "092b0244-375c-459b-82eb-1373bbf50b25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(losses): 7351\n",
      "loss_mean: 0.3091465074915113\n",
      "loss_standard_deviation: 0.32274408025982587\n"
     ]
    }
   ],
   "source": [
    "autoencoder.pretrain(X_normal, optimizer=torch.optim.Adam(autoencoder.parameters(), lr=1e-4,  weight_decay=0.01), loss_function=RMSELoss(), num_epochs=100, batch_size=64, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "35f831a2-a278-4365-8aae-5429fccc5b05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 90.24\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 97.57\\%    & 96.86\\%        & 100.00\\%       & 98.41\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# With batch norm and GELU and 64 x 32 nodes\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "99803832-aa8c-40e4-8225-1315b6e4ba0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 86.71\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 54.35\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 13.50\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 76.74\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 82.30\\%    & 94.83\\%        & 80.84\\%        & 87.28\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# With batch norm and GELU\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a8237d2b-9494-4434-904a-07057d558b27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 84.93\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 91.72\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 18.38\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 83.04\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 86.38\\%    & 94.56\\%        & 86.86\\%        & 90.55\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# With batch norm\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431885ee-fac4-48be-9892-98a39b1f11b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ca48d029-34b1-4b1d-b110-f8b950342d00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 89.22\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 99.02\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 74.98\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 94.81\\%    & 96.43\\%        & 96.66\\%        & 96.55\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# With batch norm\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b5797913-286d-442a-a4ec-1b6c3b5102fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 84.32\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 25.94\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 11.34\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 58.10\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 77.44\\%    & 93.53\\%        & 75.16\\%        & 83.34\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# No batch norm\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04ec9a-8182-4cee-8d00-331c5f2ecb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "968d4c34-3c44-4203-9641-eb26666fe3e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 84.39\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 26.54\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 12.52\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 61.17\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 77.85\\%    & 93.59\\%        & 75.67\\%        & 83.68\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# 8 neurons bottlekneck\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94f0f2c8-4ef8-4ec3-b7f3-f3401a654087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 84.34\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 26.29\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 11.97\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 59.80\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 77.66\\%    & 93.55\\%        & 75.44\\%        & 83.53\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "# 16 neurons bottlekneck\n",
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d8bf00d9-d29c-43d1-b406-ef1369c9694e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(losses): 7351\n",
      "loss_mean: 0.5267899247204879\n",
      "loss_standard_deviation: 0.42480818090509104\n"
     ]
    }
   ],
   "source": [
    "autoencoder.pretrain(X_normal, optimizer=torch.optim.Adam(autoencoder.parameters(), lr=1e-4,  weight_decay=0.01), loss_function=RMSELoss(), num_epochs=100, batch_size=64, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e9aa93c-cc4d-44b2-b799-b72c3de776a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 87.82\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 99.70\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 81.57\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 95.16\\%    & 96.02\\%        & 97.60\\%        & 96.80\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1085b2ac-4c75-49c2-9341-3b0c24c423bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 87.36\\%    & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 99.84\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 92.63\\%    & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 96.12\\%    & 95.94\\%        & 99.03\\%        & 97.46\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e5db2778-1350-40b4-b3e8-8a4f0ba56737",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(losses): 7351\n",
      "loss_mean: 0.009242754975595305\n",
      "loss_standard_deviation: 0.008484621480753409\n"
     ]
    }
   ],
   "source": [
    "autoencoder.pretrain(X_normal, optimizer=torch.optim.Adam(autoencoder.parameters(), lr=1e-4,  weight_decay=0.01), loss_function=torch.nn.MSELoss(reduction=\"mean\"), num_epochs=100, batch_size=64, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f7f968c5-ebbf-46fd-a4bc-c9ba57d3478e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14702\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5698\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7358\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4312\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "7704\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "5687\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "4162\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "9381\n",
      "Using n_std: 0.5 as prediction threshold\n",
      "-----------\n",
      "\\begin{tabular}{lllllr}\n",
      "\\hline\n",
      " Behavior                 & Accuracy   & Precision      & Recall         & F1-Score       &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & 0.00\\%     & \\notCalculated & \\notCalculated & \\notCalculated &       14702 \\\\\n",
      " ROOTKIT\\_BDVL            & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        5698 \\\\\n",
      " ROOTKIT\\_BEURK           & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7358 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4312 \\\\\n",
      " CNC\\_THETICK             & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        7704 \\\\\n",
      " CNC\\_OPT1                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        5687 \\\\\n",
      " CNC\\_OPT2                & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        4162 \\\\\n",
      " RANSOMWARE\\_POC          & 100.00\\%   & \\notCalculated & \\notCalculated & \\notCalculated &        9381 \\\\\n",
      " GLOBAL                   & 75.08\\%    & 75.08\\%        & 100.00\\%       & 85.77\\%        &       59004 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "evaluation_data = scaled_dataset\n",
    "autoencoder.evaluate(evaluation_data, n_std=0.5, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "429a53ac-363e-42c5-9b70-f2494f1fda00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scaled_train_test_split(split=0.8, scaling_minmax=True, scale_normal_only=True, filter_outliers=True):\n",
    "    \"\"\"\n",
    "    Method returns dictionaries mapping behaviors to scaled train and test data, as well as the scaler used\n",
    "    Either decision states or raw behaviors can be utilized (decision flag) as no combinations\n",
    "    with mtd need to be considered\n",
    "    \"\"\"\n",
    "    #print(os.getcwd())\n",
    "    rdf = parse_no_mtd_behavior_data(filter_outliers=filter_outliers)\n",
    "    print(f\"type(rdf): {type(rdf)}\")\n",
    "    print(f\"rdf.columns: {rdf.columns}; {len(rdf.columns)}\")\n",
    "    # take split of all behaviors, concat, calc scaling, scale both train and test split\n",
    "    train_filtered, df_test = filter_train_split_for_outliers(rdf, Behavior.NORMAL, split)\n",
    "    print(f\"type(train_filtered): {type(train_filtered)}\")\n",
    "    print(f\"type(df_test): {type(df_test)}\")\n",
    "\n",
    "    # get behavior dicts for train and test\n",
    "    train_bdata = {}\n",
    "    test_bdata = {}\n",
    "    for b in rdf[\"attack\"].unique():\n",
    "        dtrain_filtered, df_test = filter_train_split_for_outliers(rdf, b, split)\n",
    "        train_bdata[b] = dtrain_filtered\n",
    "        test_bdata[b] = df_test\n",
    "        if b != Behavior.NORMAL and not scale_normal_only:\n",
    "            train_filtered = np.vstack((train_filtered, train_bdata[b]))\n",
    "\n",
    "    # fit scaler on either just normal data (if scale_normal_only), or all training data combined\n",
    "    scaler = StandardScaler() if not scaling_minmax else MinMaxScaler()\n",
    "    print(f\"Using scaler {scaler}\")\n",
    "    scaler.fit(train_filtered[:, :-1])\n",
    "\n",
    "    # get behavior dicts for scaled train and test data\n",
    "    scaled_train = {}\n",
    "    scaled_test = {}\n",
    "    for b, d in train_bdata.items():\n",
    "        scaled_train[b] = np.hstack((scaler.transform(d[:, :-1]), np.expand_dims(d[:, -1], axis=1)))\n",
    "        scaled_test[b] = np.hstack(\n",
    "            (scaler.transform(test_bdata[b][:, :-1]), np.expand_dims(test_bdata[b][:, -1], axis=1)))\n",
    "\n",
    "    # return also scaler in case of using the agent for online scaling\n",
    "    return scaled_train, scaled_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59969025-d608-4e39-b979-24e17d9c67b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(data, split=0.8):\n",
    "    row = int(len(data) * split)\n",
    "    X_train = data[:row, :-1].astype(np.float32)\n",
    "    X_valid = data[row:, :-1].astype(np.float32)\n",
    "    return X_train, X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7036512b-3624-4fd9-a274-3c2ecc1e6b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_test_dataset(test_data):\n",
    "    test_data_dict = {}\n",
    "\n",
    "    for behavior, behavior_data in test_data.items():\n",
    "        if behavior == Behavior.NORMAL:\n",
    "            behavior_data = behavior_data[:2800]\n",
    "            #continue\n",
    "        else:\n",
    "            behavior_data = behavior_data[:400]\n",
    "\n",
    "        test_data_dict[behavior] = behavior_data\n",
    "\n",
    "    return test_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f77fed7-ded2-4894-8e42-f9fb6d27ead3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting Behavior.NORMAL\n",
      "getting Behavior.RANSOMWARE_POC\n",
      "getting Behavior.ROOTKIT_BDVL\n",
      "getting Behavior.ROOTKIT_BEURK\n",
      "getting Behavior.CNC_THETICK\n",
      "getting Behavior.CNC_BACKDOOR_JAKORITAR\n",
      "getting Behavior.CNC_OPT1\n",
      "getting Behavior.CNC_OPT2\n",
      "type(rdf): <class 'pandas.core.frame.DataFrame'>\n",
      "rdf.columns: Index(['connectivity', 'cpuUser', 'cpuSystem', 'cpuIdle', 'cpuIowait',\n",
      "       'cpuSoftIrq', 'tasks', 'tasksRunning', 'tasksSleeping', 'tasksZombie',\n",
      "       'ramFree', 'ramUsed', 'ramCache', 'memAvail', 'iface0RX', 'iface0TX',\n",
      "       'iface1RX', 'iface1TX', 'numEncrypted', 'block:block_bio_backmerge',\n",
      "       'block:block_bio_remap', 'block:block_dirty_buffer',\n",
      "       'block:block_getrq', 'block:block_touch_buffer', 'block:block_unplug',\n",
      "       'clk:clk_set_rate', 'cpu-migrations', 'cs', 'fib:fib_table_lookup',\n",
      "       'filemap:mm_filemap_add_to_page_cache', 'gpio:gpio_value',\n",
      "       'ipi:ipi_raise', 'irq:irq_handler_entry', 'irq:softirq_entry',\n",
      "       'jbd2:jbd2_handle_start', 'jbd2:jbd2_start_commit', 'kmem:kfree',\n",
      "       'kmem:kmalloc', 'kmem:kmem_cache_alloc', 'kmem:kmem_cache_free',\n",
      "       'kmem:mm_page_alloc', 'kmem:mm_page_alloc_zone_locked',\n",
      "       'kmem:mm_page_free', 'kmem:mm_page_pcpu_drain', 'mmc:mmc_request_start',\n",
      "       'net:net_dev_queue', 'net:net_dev_xmit', 'net:netif_rx', 'page-faults',\n",
      "       'pagemap:mm_lru_insertion', 'preemptirq:irq_enable',\n",
      "       'qdisc:qdisc_dequeue', 'random:get_random_bytes',\n",
      "       'random:mix_pool_bytes_nolock', 'random:urandom_read',\n",
      "       'raw_syscalls:sys_enter', 'raw_syscalls:sys_exit', 'rpm:rpm_resume',\n",
      "       'rpm:rpm_suspend', 'sched:sched_process_exec',\n",
      "       'sched:sched_process_free', 'sched:sched_process_wait',\n",
      "       'sched:sched_switch', 'sched:sched_wakeup', 'signal:signal_deliver',\n",
      "       'signal:signal_generate', 'skb:consume_skb', 'skb:kfree_skb',\n",
      "       'skb:skb_copy_datagram_iovec', 'sock:inet_sock_set_state',\n",
      "       'task:task_newtask', 'tcp:tcp_destroy_sock', 'tcp:tcp_probe',\n",
      "       'timer:hrtimer_start', 'timer:timer_start',\n",
      "       'workqueue:workqueue_activate_work', 'writeback:global_dirty_state',\n",
      "       'writeback:sb_clear_inode_writeback', 'writeback:wbc_writepage',\n",
      "       'writeback:writeback_dirty_inode',\n",
      "       'writeback:writeback_dirty_inode_enqueue',\n",
      "       'writeback:writeback_dirty_page',\n",
      "       'writeback:writeback_mark_inode_dirty',\n",
      "       'writeback:writeback_pages_written', 'writeback:writeback_single_inode',\n",
      "       'writeback:writeback_write_inode', 'writeback:writeback_written',\n",
      "       'attack'],\n",
      "      dtype='object'); 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n",
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_filtered): <class 'numpy.ndarray'>\n",
      "type(df_test): <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n",
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n",
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n",
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n",
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n",
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n",
      "/var/folders/8v/42fl0kws5cs5j84mbf8mbhbh0000gn/T/ipykernel_22746/2293243636.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_filtered[\"attack\"] = b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scaler MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "training_data, test_data, _ = get_scaled_train_test_split(scaling_minmax=True,\n",
    "                                                                         scale_normal_only=True)\n",
    "normal_data = training_data[Behavior.NORMAL]\n",
    "threshold = int(len(normal_data) * 0.5)\n",
    "\n",
    "training_data[Behavior.NORMAL] = normal_data[:threshold]\n",
    "\n",
    "ae_training_data = normal_data[threshold:]  # use remaining samples for autoencoder\n",
    "ae_training_x, ae_valid_x = split_data(ae_training_data)\n",
    "\n",
    "N_FEATURES = normal_data.shape[1] -1\n",
    "flattend_test_data = np.empty([0, N_FEATURES+1])\n",
    "for behavior, behavior_data in test_data.items():\n",
    "    if behavior == Behavior.NORMAL:\n",
    "        NR_SAMPLES = 2800\n",
    "        behavior_data[:, -1] =  0\n",
    "    else:\n",
    "        NR_SAMPLES = 400\n",
    "        behavior_data[:, -1] = 1\n",
    "    #y_true = np.array([0 if behavior == Behavior.NORMAL else 1] * NR_SAMPLES)\n",
    "    \n",
    "    flattend_test_data = np.concatenate((flattend_test_data, behavior_data[:NR_SAMPLES]), axis=0)\n",
    "\n",
    "ae_test_x = flattend_test_data[:,:-1]\n",
    "ae_test_y = flattend_test_data[:,-1].astype(int)\n",
    "\n",
    "evaluation_data = {}\n",
    "for behavior, behavior_data in training_data.items():\n",
    "    if behavior == Behavior.NORMAL:\n",
    "        evaluation_data[behavior] = behavior_data[:2800]\n",
    "    else:\n",
    "        evaluation_data[behavior] = behavior_data[:400]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FedRL-for-IT-Sec",
   "language": "python",
   "name": "fedrl-for-it-sec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
