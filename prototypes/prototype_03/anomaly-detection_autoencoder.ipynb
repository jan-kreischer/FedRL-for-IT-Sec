{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba26052c-2bb9-48c9-9565-ed139cc65688",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prototype 02 > Experiment 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6ff0e9-c775-4ed1-ae4f-f2a8f8f9a665",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOKaMgUnZYbP",
    "outputId": "240f59de-2be0-483f-d1db-521468987b62"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mount your google drive in google colab\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      3\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Mount your google drive in google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45f179-6ddf-4960-929e-aba796d587c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to base directory\n",
    "%cd /content/drive/MyDrive/University/Master-Thesis/Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e796890-58dd-4f17-bf30-0e3ca852201e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "executed_yet = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0562da66-4301-4ed6-a99f-174d247c8cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original working directory: /Users/jankreischer/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code/prototypes/prototype_03\n",
      "Current working directory: /Users/jankreischer/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not executed_yet:\n",
    "    executed_yet = True\n",
    "    original_working_directory_path = os.getcwd()\n",
    "    os.chdir(os.path.join(original_working_directory_path, \"../..\"))\n",
    "    root_working_directory_path =  os.getcwd()\n",
    "    \n",
    "print(f'Original working directory: {original_working_directory_path}')\n",
    "print(f'Current working directory: {root_working_directory_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80523a04-4e7d-47de-8c6f-4d0c6c77d05a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## --- Dependencies ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889a4ea2-121e-4ad0-8bf6-03b5b30e86f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Dependencies\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63770f25-75fb-4b9d-8ea3-51354c8152dd",
   "metadata": {
    "id": "63770f25-75fb-4b9d-8ea3-51354c8152dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jankreischer/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Global Dependencies\n",
    "from src.functions import calculate_balance_metrics\n",
    "from src.custom_types import Behavior, MTDTechnique, actions, mitigated_by, normal_afterstates\n",
    "from src.data_provider import DataProvider\n",
    "from src.enums import Execution, Evaluation\n",
    "from src.evaluation_utils import plot_learning, seed_random, get_pretrained_agent, evaluate_agent, evaluate_agent_on_afterstates\n",
    "from src.autoencoder_utils import evaluate_ae_on_afterstates, evaluate_ae_on_no_mtd_behavior, pretrain_ae_model, \\\n",
    "    evaluate_all_ds_as_ae_models, pretrain_all_ds_as_ae_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "580f9cb8-76ea-4408-81e9-94d910c3b356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from prototypes.prototype_02.agent import Agent\n",
    "#from prototypes.prototype_02.client import Client\n",
    "#from prototypes.prototype_02.server import Server\n",
    "#from prototypes.prototype_02.experiment import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f16cde5a-acb4-4b13-820c-0345c75f385d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17332\n",
      "60549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "decision_states_dataset = pd.read_csv('prototypes/prototype_03/dataset-02_decision-state-samples.csv')\n",
    "print(len(decision_states_dataset))\n",
    "after_states_dataset = pd.read_csv('prototypes/prototype_03/dataset-02_after-state-samples.csv')\n",
    "print(len(after_states_dataset))\n",
    "dataset = pd.concat([decision_states_dataset, after_states_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9baf9c7-f76e-49be-8ef0-56b30c8e94c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['None'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_states_dataset[\"mtd\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74cb649b-379a-4a58-ad13-622752fc4b27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3 Status Features\n",
    "time_status_columns = ['time', 'timestamp', 'seconds']\n",
    "try:\n",
    "    dataset.drop(time_status_columns, inplace=True, axis=1)\n",
    "except:\n",
    "    print(\"All time status features are removed from the dataset\")\n",
    "assert len(dataset.columns) == 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8591552-9118-4acc-9f84-fab7e47ddad2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cachefiles:cachefiles_lookup', 'cachefiles:cachefiles_mark_active', 'dma_fence:dma_fence_init', 'alarmtimer:alarmtimer_fired', 'cachefiles:cachefiles_create', 'tasksStopped', 'connectivity', 'clk:clk_set_rate', 'cpuHardIrq', 'udp:udp_fail_queue_rcv_skb', 'alarmtimer:alarmtimer_start', 'cpuNice'}\n",
      "(77881, 87)\n"
     ]
    }
   ],
   "source": [
    "from fast_ml.feature_selection import get_constant_features\n",
    "\n",
    "constant_features = set(get_constant_features(dataset, threshold=0.99, dropna=False)['Var'])\n",
    "print(constant_features)\n",
    "try:\n",
    "    dataset.drop(constant_features, inplace=True, axis=1)\n",
    "except:\n",
    "    print(\"All constant features are removed from the dataset\")\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7cce8d-bddd-45bc-b8f2-f863db79281a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal_afterstate_strings = [\n",
    "    (\"Behavior.ROOTKIT_BDVL\", \"MTDTechnique.ROOTKIT_SANITIZER\"),\n",
    "    (\"Behavior.ROOTKIT_BEURK\", \"MTDTechnique.ROOTKIT_SANITIZER\"),\n",
    "    (\"Behavior.RANSOMWARE_POC\", \"MTDTechnique.RANSOMWARE_DIRTRAP\"),\n",
    "    (\"Behavior.RANSOMWARE_POC\", \"MTDTechnique.RANSOMWARE_FILE_EXT_HIDE\"),\n",
    "    (\"Behavior.CNC_BACKDOOR_JAKORITAR\", \"MTDTechnique.CNC_IP_SHUFFLE\"),\n",
    "    (\"Behavior.CNC_THETICK\", \"MTDTechnique.CNC_IP_SHUFFLE\"),\n",
    "    (\"Behavior.CNC_OPT1\", \"MTDTechnique.CNC_IP_SHUFFLE\"),\n",
    "    (\"Behavior.CNC_OPT2\", \"MTDTechnique.CNC_IP_SHUFFLE\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbaed76-55cb-435b-afd3-f445de23c0ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Behavior.NORMAL', 'Behavior.RANSOMWARE_POC',\n",
       "       'Behavior.ROOTKIT_BDVL', 'Behavior.CNC_BACKDOOR_JAKORITAR',\n",
       "       'Behavior.ROOTKIT_BEURK', 'Behavior.CNC_THETICK',\n",
       "       'Behavior.CNC_OPT1', 'Behavior.CNC_OPT2'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"behavior\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3368fd12-df1f-48ee-9573-e2cf71fa34d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_normal(sample):  \n",
    "    behavior = sample.behavior \n",
    "    mtd = sample.mtd\n",
    "    if behavior == \"Behavior.NORMAL\":\n",
    "        label = 0\n",
    "    elif (str(behavior), str(mtd)) in normal_afterstate_strings:\n",
    "        #print(f\"normal afterstate for {behavior} and {mtd}\")\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2647ec7-1f7b-49e8-911d-a87302915ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add a label if a state should be considered normal or not\n",
    "dataset['is_normal'] = dataset.apply(lambda sample: is_normal(sample), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b0c8744-57ee-4c44-9a11-2c0fe67581af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38940\n",
      "38941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rl_dataset, ae_dataset = train_test_split(dataset, train_size=0.5, shuffle=True)\n",
    "print(len(rl_dataset))\n",
    "print(len(ae_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa2bf827-606e-42f1-bd6f-21be1dd25581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior.NORMAL, None : labeled [0] (2057 samples)\n",
      "Behavior.NORMAL, MTDTechnique.CNC_IP_SHUFFLE : labeled [0] (973 samples)\n",
      "Behavior.NORMAL, MTDTechnique.ROOTKIT_SANITIZER : labeled [0] (995 samples)\n",
      "Behavior.NORMAL, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [0] (1061 samples)\n",
      "Behavior.NORMAL, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [0] (970 samples)\n",
      "Behavior.ROOTKIT_BDVL, None : labeled [1] (785 samples)\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.CNC_IP_SHUFFLE : labeled [1] (327 samples)\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.ROOTKIT_SANITIZER : labeled [0] (993 samples)\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [1] (662 samples)\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [1] (284 samples)\n",
      "Behavior.ROOTKIT_BEURK, None : labeled [1] (1048 samples)\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.CNC_IP_SHUFFLE : labeled [1] (974 samples)\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.ROOTKIT_SANITIZER : labeled [0] (1075 samples)\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [1] (965 samples)\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [1] (1005 samples)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, None : labeled [1] (1043 samples)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.CNC_IP_SHUFFLE : labeled [0] (1041 samples)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.ROOTKIT_SANITIZER : labeled [1] (1060 samples)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [1] (1019 samples)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [1] (997 samples)\n",
      "Behavior.CNC_THETICK, None : labeled [1] (739 samples)\n",
      "Behavior.CNC_THETICK, MTDTechnique.CNC_IP_SHUFFLE : labeled [0] (1032 samples)\n",
      "Behavior.CNC_THETICK, MTDTechnique.ROOTKIT_SANITIZER : labeled [1] (1033 samples)\n",
      "Behavior.CNC_THETICK, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [1] (1044 samples)\n",
      "Behavior.CNC_THETICK, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [1] (1052 samples)\n",
      "Behavior.CNC_OPT1, None : labeled [1] (1072 samples)\n",
      "Behavior.CNC_OPT1, MTDTechnique.CNC_IP_SHUFFLE : labeled [0] (1054 samples)\n",
      "Behavior.CNC_OPT1, MTDTechnique.ROOTKIT_SANITIZER : labeled [1] (1070 samples)\n",
      "Behavior.CNC_OPT1, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [1] (1089 samples)\n",
      "Behavior.CNC_OPT1, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [1] (1088 samples)\n",
      "Behavior.CNC_OPT2, None : labeled [1] (1041 samples)\n",
      "Behavior.CNC_OPT2, MTDTechnique.CNC_IP_SHUFFLE : labeled [0] (1008 samples)\n",
      "Behavior.CNC_OPT2, MTDTechnique.ROOTKIT_SANITIZER : labeled [1] (1045 samples)\n",
      "Behavior.CNC_OPT2, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [1] (1039 samples)\n",
      "Behavior.CNC_OPT2, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [1] (1036 samples)\n",
      "Behavior.RANSOMWARE_POC, None : labeled [1] (909 samples)\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.CNC_IP_SHUFFLE : labeled [1] (319 samples)\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.ROOTKIT_SANITIZER : labeled [1] (852 samples)\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.RANSOMWARE_DIRTRAP : labeled [0] (1048 samples)\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : labeled [0] (1036 samples)\n"
     ]
    }
   ],
   "source": [
    "for behavior in Behavior:\n",
    "    for mtd in [\"None\"] + list(MTDTechnique):\n",
    "        behavior_samples = rl_dataset.loc[(rl_dataset['behavior'] == str(behavior)) & (rl_dataset['mtd'] == str(mtd))]\n",
    "        print(f\"{behavior}, {mtd} : labeled {behavior_samples['is_normal'].unique()} ({len(behavior_samples)} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8eed50d-fa70-4417-82bf-066c420b379c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14433, 85)\n"
     ]
    }
   ],
   "source": [
    "ae_normal_x = ae_dataset.loc[ae_dataset[\"is_normal\"] == 0].drop([\"behavior\", \"mtd\", \"is_normal\"],  axis=1, inplace=False).to_numpy().astype(np.float32) \n",
    "print(ae_normal_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f83971a-3571-4b55-9bac-475fce673704",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9621, 85)\n",
      "(4812, 85)\n"
     ]
    }
   ],
   "source": [
    "threshold = int(0.6666*len(ae_normal_x))\n",
    "ae_train_x = ae_normal_x[:threshold]\n",
    "ae_valid_x = ae_normal_x[threshold:]\n",
    "print(ae_train_x.shape)\n",
    "print(ae_valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e70eb392-28d2-4589-9cf9-caeadf575df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report, accuracy_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = torch.nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "class AutoEncoder(torch.nn.Module):\n",
    "    \n",
    "\n",
    "    def __init__(self, X_valid, evaluation_data, n_stds=[1], n_hidden_1=64, n_hidden_2=32, activation_function=nn.GELU(), batch_size: int = 64, verbose=False):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        validation_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(X_valid).type(torch.float),\n",
    "\n",
    "        )\n",
    "        self.validation_data_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=1, shuffle=True, drop_last=True)\n",
    "\n",
    "        self.y_test = evaluation_data[[\"is_normal\"]].to_numpy().astype(np.float32) \n",
    "        self.X_test = evaluation_data.drop([\"behavior\", \"mtd\", \"is_normal\"],  axis=1, inplace=False).to_numpy().astype(np.float32) \n",
    "        \n",
    "        self.evaluation_data = evaluation_data\n",
    "        self.n_stds = n_stds\n",
    "        \n",
    "        n_features = X_valid.shape[1]\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_features, n_hidden_1),\n",
    "            nn.BatchNorm1d(n_hidden_1),\n",
    "            activation_function,\n",
    "            nn.Linear(n_hidden_1, n_hidden_2),\n",
    "            activation_function,\n",
    "            #nn.Linear(32, 16),\n",
    "            #activation_function,\n",
    "            #nn.Linear(16, 32),\n",
    "            #activation_function,\n",
    "            nn.Linear(n_hidden_2, n_hidden_1),\n",
    "            nn.BatchNorm1d(n_hidden_1),\n",
    "            activation_function,\n",
    "            nn.Linear(n_hidden_1, n_features),\n",
    "            activation_function\n",
    "        )\n",
    "        self.threshold = None\n",
    "        self.loss_mean = None\n",
    "        self.loss_standard_deviation = None\n",
    "        \n",
    "        self.verbose = verbose\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "    \n",
    "    \n",
    "    def pretrain(self, X_train, optimizer=torch.optim.SGD, loss_function=torch.nn.MSELoss(reduction='mean'), num_epochs: int = 15, batch_size=64, verbose=False):\n",
    "        \n",
    "        training_dataset = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(X_train).type(torch.float),\n",
    "        )\n",
    "        training_data_loader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "        epoch_losses = []\n",
    "        #for e in tqdm(range(num_epochs), unit=\"epoch\", leave=False):\n",
    "        for e in range(num_epochs):\n",
    "            self.train()\n",
    "            current_losses = []\n",
    "            for batch_index, (inputs,) in enumerate(training_data_loader):\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = loss_function(inputs, outputs)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                current_losses.append(loss.item())\n",
    "            \n",
    "            epoch_losses.append(np.average(current_losses))\n",
    "            if verbose:\n",
    "                print(f'Training Loss in epoch {e + 1}: {epoch_losses[e]}')\n",
    "            \n",
    "        self.analyze_loss()\n",
    "\n",
    "    '''\n",
    "    This function uses normal data samles \n",
    "    after training the autoencoder to determine\n",
    "    values that can be considered normal\n",
    "    for the reconstruction loss based on normal samples\n",
    "    '''\n",
    "    def analyze_loss(self):\n",
    "        losses = []\n",
    "        \n",
    "        self.eval() \n",
    "        with torch.no_grad():\n",
    "            loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "            for batch_index, (inputs,) in enumerate(self.validation_data_loader):\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = loss_function(inputs, outputs)\n",
    "                losses.append(loss.item())\n",
    "        \n",
    "        losses = np.array(losses)\n",
    "\n",
    "        self.loss_mean = losses.mean()\n",
    "        self.loss_standard_deviation = losses.std()\n",
    "\n",
    "        \n",
    "    def predict(self, x, n_std = 1):\n",
    "        test_data = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(x).type(torch.float32)\n",
    "        )\n",
    "        test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "        all_predictions = torch.tensor([])  # .cuda()\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            ae_loss = torch.nn.MSELoss(reduction=\"sum\")\n",
    "            for idx, (batch_x,) in enumerate(test_data_loader):\n",
    "                model_predictions = self.forward(batch_x)\n",
    "                model_predictions = ae_loss(model_predictions, batch_x).unsqueeze(0)  # unsqueeze as batch_size set to 1\n",
    "                all_predictions = torch.cat((all_predictions, model_predictions))\n",
    "\n",
    "        threshold = self.loss_mean + n_std * self.loss_standard_deviation\n",
    "        all_predictions = (all_predictions > threshold).type(torch.long)\n",
    "        return all_predictions.flatten()\n",
    "    \n",
    "    \n",
    "    def predict_deviation(self, x):\n",
    "        test_data = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(x).type(torch.float32)\n",
    "        )\n",
    "        test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "        prediction_errors = torch.tensor([])\n",
    "        loss_function = torch.nn.MSELoss(reduction=\"sum\")\n",
    "        \n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for batch_index, (inputs,) in enumerate(test_data_loader):\n",
    "                prediction = self.forward(inputs)\n",
    "                prediction_error = loss_function(inputs, prediction).unsqueeze(0)  # unsqueeze as batch_size set to 1\n",
    "                prediction_errors = torch.cat((prediction_errors, prediction_error))\n",
    "\n",
    "        return prediction_errors\n",
    "    \n",
    "    \n",
    "    def score(self):\n",
    "        n_std, accuracy = self.accuracy_score(None, None)\n",
    "        if self.verbose:\n",
    "            print(f\">> Highest validation accuracy achieved {accuracy:.2f} with n_std={n_std} <<\")\n",
    "            self.evaluate(n_std)\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def accuracy_score(self, X, y):\n",
    "        #if not self.threshold:\n",
    "        #loss_mean, loss_standard_deviation = self.analyze_loss(X)\n",
    "        #n_stds = np.arange(0.1, 3, 0.1)\n",
    "        if self.loss_mean == None or self.loss_standard_deviation == None:\n",
    "              #print(\"accuracy_score_optimized > accurcy_loss()\")\n",
    "              self.analyze_loss()\n",
    "    \n",
    "        best_accuracy = 0\n",
    "        best_n_std = 0\n",
    "        #accuracies = []\n",
    "        y_dev = self.predict_deviation((self.X_test).astype(np.float32))\n",
    "        for n_std in self.n_stds:\n",
    "            y_true = self.y_test\n",
    "            threshold = self.loss_mean + n_std * self.loss_standard_deviation\n",
    "            y_pred = (y_dev > threshold).type(torch.long).detach().cpu().numpy()\n",
    "            \n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_n_std = n_std\n",
    "            #if self.verbose:\n",
    "            #    print(f\"n_std {n_std:.2f} -> accuracy: {accuracy}\")\n",
    "\n",
    "        return best_n_std, best_accuracy\n",
    "    \n",
    "    def evaluate(self, n_std=1, tablefmt='pipe'):\n",
    "        results = []\n",
    "        headers=[\"Behavior\", \"Type\", \"After MTD\", \"Accuracy\", \"\\#Samples\"]\n",
    "        \n",
    "        y_true_total = np.empty([0])\n",
    "        y_pred_total = np.empty([0])\n",
    "        \n",
    "        for behavior in Behavior:\n",
    "            for mtd in [\"None\"] + list(MTDTechnique):\n",
    "                behavior_samples = self.evaluation_data.loc[(self.evaluation_data['behavior'] == str(behavior)) & (self.evaluation_data['mtd'] == str(mtd))]\n",
    "                \n",
    "                y_true= behavior_samples[[\"is_normal\"]].to_numpy().flatten().astype(np.float32) \n",
    "                #print(y_true.shape)\n",
    "                #print(y_true_total.shape)\n",
    "                y_true_total = np.concatenate((y_true_total, y_true))\n",
    "                \n",
    "                X_test = behavior_samples.drop([\"behavior\", \"mtd\", \"is_normal\"],  axis=1, inplace=False).to_numpy().astype(np.float32) \n",
    "                \n",
    "                y_pred = self.predict(X_test, n_std=n_std)\n",
    "                print(f\"{behavior}, {mtd} : Predicted {len(y_pred)} for {len(X_test)} given samples\")\n",
    "                y_pred_total = np.concatenate((y_pred_total, y_pred))\n",
    "                \n",
    "                accuracy = accuracy_score(y_true, y_pred)\n",
    "            \n",
    "                n_samples = len(y_true)\n",
    "                \n",
    "                if mtd == 'None':\n",
    "                    state_type = \"Decision\"\n",
    "                else:\n",
    "                    state_type = \"After\"\n",
    "                results.append([behavior.name.replace('_', '\\_'), state_type, str(mtd), f'{(100 * accuracy):.2f}\\%', str(n_samples)])\n",
    "                \n",
    "        print(tabulate(results, headers=headers, tablefmt=tablefmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a542c845-042a-45ee-8ccc-5144a0f5b08e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder(ae_valid_x, rl_dataset, n_hidden_1=64, n_hidden_2=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e206630c-8cde-4a73-a48d-96892936a533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss in epoch 1: 275886.25354166667\n",
      "Training Loss in epoch 2: 275870.97541666665\n",
      "Training Loss in epoch 3: 275890.76895833336\n",
      "Training Loss in epoch 4: 275889.43083333335\n",
      "Training Loss in epoch 5: 275877.80645833333\n",
      "Training Loss in epoch 6: 275899.6375\n",
      "Training Loss in epoch 7: 275874.7054166667\n",
      "Training Loss in epoch 8: 275880.12\n",
      "Training Loss in epoch 9: 275894.1039583333\n",
      "Training Loss in epoch 10: 275890.2972916667\n",
      "Training Loss in epoch 11: 275896.2233333333\n",
      "Training Loss in epoch 12: 275879.7058333333\n",
      "Training Loss in epoch 13: 275877.7495833333\n",
      "Training Loss in epoch 14: 275892.105625\n",
      "Training Loss in epoch 15: 275898.4889583333\n",
      "Training Loss in epoch 16: 275885.1820833333\n",
      "Training Loss in epoch 17: 275884.78770833334\n",
      "Training Loss in epoch 18: 275889.54270833335\n",
      "Training Loss in epoch 19: 275881.138125\n",
      "Training Loss in epoch 20: 275880.411875\n",
      "Training Loss in epoch 21: 275892.218125\n",
      "Training Loss in epoch 22: 275875.866875\n",
      "Training Loss in epoch 23: 275861.18145833333\n",
      "Training Loss in epoch 24: 275899.18625\n",
      "Training Loss in epoch 25: 275876.2008333333\n",
      "Training Loss in epoch 26: 275889.87666666665\n",
      "Training Loss in epoch 27: 275874.56416666665\n",
      "Training Loss in epoch 28: 275861.45229166665\n",
      "Training Loss in epoch 29: 275881.1147916667\n",
      "Training Loss in epoch 30: 275894.64458333334\n",
      "Training Loss in epoch 31: 275871.27\n",
      "Training Loss in epoch 32: 275883.39979166666\n",
      "Training Loss in epoch 33: 275872.9214583333\n",
      "Training Loss in epoch 34: 275863.2866666667\n",
      "Training Loss in epoch 35: 275865.723125\n",
      "Training Loss in epoch 36: 275874.77458333335\n",
      "Training Loss in epoch 37: 275886.29\n",
      "Training Loss in epoch 38: 275868.5704166667\n",
      "Training Loss in epoch 39: 275899.62666666665\n",
      "Training Loss in epoch 40: 275873.17354166665\n",
      "Training Loss in epoch 41: 275880.35375\n",
      "Training Loss in epoch 42: 275873.975625\n",
      "Training Loss in epoch 43: 275863.54604166665\n",
      "Training Loss in epoch 44: 275886.825\n",
      "Training Loss in epoch 45: 275873.15708333335\n",
      "Training Loss in epoch 46: 275875.28979166667\n",
      "Training Loss in epoch 47: 275862.89458333334\n",
      "Training Loss in epoch 48: 275862.02875\n",
      "Training Loss in epoch 49: 275873.98354166665\n",
      "Training Loss in epoch 50: 275854.548125\n",
      "Training Loss in epoch 51: 275860.99104166665\n",
      "Training Loss in epoch 52: 275877.21729166666\n",
      "Training Loss in epoch 53: 275867.32375\n",
      "Training Loss in epoch 54: 275866.5754166667\n",
      "Training Loss in epoch 55: 275859.59270833334\n",
      "Training Loss in epoch 56: 275869.77229166665\n",
      "Training Loss in epoch 57: 275853.03208333335\n",
      "Training Loss in epoch 58: 275863.0989583333\n",
      "Training Loss in epoch 59: 275864.8277083333\n",
      "Training Loss in epoch 60: 275860.68854166666\n",
      "Training Loss in epoch 61: 275855.735\n",
      "Training Loss in epoch 62: 275864.8525\n",
      "Training Loss in epoch 63: 275864.569375\n",
      "Training Loss in epoch 64: 275871.0179166667\n",
      "Training Loss in epoch 65: 275853.484375\n",
      "Training Loss in epoch 66: 275855.266875\n",
      "Training Loss in epoch 67: 275859.42333333334\n",
      "Training Loss in epoch 68: 275871.0925\n",
      "Training Loss in epoch 69: 275870.63625\n"
     ]
    }
   ],
   "source": [
    "autoencoder.pretrain(ae_train_x, optimizer=torch.optim.Adam(autoencoder.parameters(), lr=1e-4,  weight_decay=0.01), loss_function=RMSELoss(), num_epochs=100, batch_size=64, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8ce4b1d-bb3a-40ef-a21a-68b4d1852496",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior.NORMAL, None : Predicted 2057 for 2057 given samples\n",
      "Behavior.NORMAL, MTDTechnique.CNC_IP_SHUFFLE : Predicted 973 for 973 given samples\n",
      "Behavior.NORMAL, MTDTechnique.ROOTKIT_SANITIZER : Predicted 995 for 995 given samples\n",
      "Behavior.NORMAL, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 1061 for 1061 given samples\n",
      "Behavior.NORMAL, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 970 for 970 given samples\n",
      "Behavior.ROOTKIT_BDVL, None : Predicted 785 for 785 given samples\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.CNC_IP_SHUFFLE : Predicted 327 for 327 given samples\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.ROOTKIT_SANITIZER : Predicted 993 for 993 given samples\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 662 for 662 given samples\n",
      "Behavior.ROOTKIT_BDVL, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 284 for 284 given samples\n",
      "Behavior.ROOTKIT_BEURK, None : Predicted 1048 for 1048 given samples\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.CNC_IP_SHUFFLE : Predicted 974 for 974 given samples\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.ROOTKIT_SANITIZER : Predicted 1075 for 1075 given samples\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 965 for 965 given samples\n",
      "Behavior.ROOTKIT_BEURK, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 1005 for 1005 given samples\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, None : Predicted 1043 for 1043 given samples\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.CNC_IP_SHUFFLE : Predicted 1041 for 1041 given samples\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.ROOTKIT_SANITIZER : Predicted 1060 for 1060 given samples\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 1019 for 1019 given samples\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 997 for 997 given samples\n",
      "Behavior.CNC_THETICK, None : Predicted 739 for 739 given samples\n",
      "Behavior.CNC_THETICK, MTDTechnique.CNC_IP_SHUFFLE : Predicted 1032 for 1032 given samples\n",
      "Behavior.CNC_THETICK, MTDTechnique.ROOTKIT_SANITIZER : Predicted 1033 for 1033 given samples\n",
      "Behavior.CNC_THETICK, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 1044 for 1044 given samples\n",
      "Behavior.CNC_THETICK, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 1052 for 1052 given samples\n",
      "Behavior.CNC_OPT1, None : Predicted 1072 for 1072 given samples\n",
      "Behavior.CNC_OPT1, MTDTechnique.CNC_IP_SHUFFLE : Predicted 1054 for 1054 given samples\n",
      "Behavior.CNC_OPT1, MTDTechnique.ROOTKIT_SANITIZER : Predicted 1070 for 1070 given samples\n",
      "Behavior.CNC_OPT1, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 1089 for 1089 given samples\n",
      "Behavior.CNC_OPT1, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 1088 for 1088 given samples\n",
      "Behavior.CNC_OPT2, None : Predicted 1041 for 1041 given samples\n",
      "Behavior.CNC_OPT2, MTDTechnique.CNC_IP_SHUFFLE : Predicted 1008 for 1008 given samples\n",
      "Behavior.CNC_OPT2, MTDTechnique.ROOTKIT_SANITIZER : Predicted 1045 for 1045 given samples\n",
      "Behavior.CNC_OPT2, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 1039 for 1039 given samples\n",
      "Behavior.CNC_OPT2, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 1036 for 1036 given samples\n",
      "Behavior.RANSOMWARE_POC, None : Predicted 909 for 909 given samples\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.CNC_IP_SHUFFLE : Predicted 319 for 319 given samples\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.ROOTKIT_SANITIZER : Predicted 852 for 852 given samples\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.RANSOMWARE_DIRTRAP : Predicted 1048 for 1048 given samples\n",
      "Behavior.RANSOMWARE_POC, MTDTechnique.RANSOMWARE_FILE_EXT_HIDE : Predicted 1036 for 1036 given samples\n",
      "\\begin{tabular}{llllr}\n",
      "\\hline\n",
      " Behavior                 & Type   & After MTD                             & Accuracy   &   \\#Samples \\\\\n",
      "\\hline\n",
      " NORMAL                   & After  & None                                  & 92.66\\%    &        2057 \\\\\n",
      " NORMAL                   & After  & MTDTechnique.CNC_IP_SHUFFLE           & 100.00\\%   &         973 \\\\\n",
      " NORMAL                   & After  & MTDTechnique.ROOTKIT_SANITIZER        & 100.00\\%   &         995 \\\\\n",
      " NORMAL                   & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 98.96\\%    &        1061 \\\\\n",
      " NORMAL                   & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 100.00\\%   &         970 \\\\\n",
      " ROOTKIT\\_BDVL            & After  & None                                  & 10.32\\%    &         785 \\\\\n",
      " ROOTKIT\\_BDVL            & After  & MTDTechnique.CNC_IP_SHUFFLE           & 10.70\\%    &         327 \\\\\n",
      " ROOTKIT\\_BDVL            & After  & MTDTechnique.ROOTKIT_SANITIZER        & 100.00\\%   &         993 \\\\\n",
      " ROOTKIT\\_BDVL            & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 0.00\\%     &         662 \\\\\n",
      " ROOTKIT\\_BDVL            & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 0.00\\%     &         284 \\\\\n",
      " ROOTKIT\\_BEURK           & After  & None                                  & 0.00\\%     &        1048 \\\\\n",
      " ROOTKIT\\_BEURK           & After  & MTDTechnique.CNC_IP_SHUFFLE           & 0.00\\%     &         974 \\\\\n",
      " ROOTKIT\\_BEURK           & After  & MTDTechnique.ROOTKIT_SANITIZER        & 100.00\\%   &        1075 \\\\\n",
      " ROOTKIT\\_BEURK           & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 0.00\\%     &         965 \\\\\n",
      " ROOTKIT\\_BEURK           & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 0.00\\%     &        1005 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & After  & None                                  & 0.00\\%     &        1043 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & After  & MTDTechnique.CNC_IP_SHUFFLE           & 100.00\\%   &        1041 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & After  & MTDTechnique.ROOTKIT_SANITIZER        & 2.55\\%     &        1060 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 0.00\\%     &        1019 \\\\\n",
      " CNC\\_BACKDOOR\\_JAKORITAR & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 0.00\\%     &         997 \\\\\n",
      " CNC\\_THETICK             & After  & None                                  & 17.86\\%    &         739 \\\\\n",
      " CNC\\_THETICK             & After  & MTDTechnique.CNC_IP_SHUFFLE           & 94.67\\%    &        1032 \\\\\n",
      " CNC\\_THETICK             & After  & MTDTechnique.ROOTKIT_SANITIZER        & 10.94\\%    &        1033 \\\\\n",
      " CNC\\_THETICK             & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 11.40\\%    &        1044 \\\\\n",
      " CNC\\_THETICK             & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 4.75\\%     &        1052 \\\\\n",
      " CNC\\_OPT1                & After  & None                                  & 5.41\\%     &        1072 \\\\\n",
      " CNC\\_OPT1                & After  & MTDTechnique.CNC_IP_SHUFFLE           & 93.64\\%    &        1054 \\\\\n",
      " CNC\\_OPT1                & After  & MTDTechnique.ROOTKIT_SANITIZER        & 4.02\\%     &        1070 \\\\\n",
      " CNC\\_OPT1                & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 4.04\\%     &        1089 \\\\\n",
      " CNC\\_OPT1                & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 3.68\\%     &        1088 \\\\\n",
      " CNC\\_OPT2                & After  & None                                  & 2.98\\%     &        1041 \\\\\n",
      " CNC\\_OPT2                & After  & MTDTechnique.CNC_IP_SHUFFLE           & 95.44\\%    &        1008 \\\\\n",
      " CNC\\_OPT2                & After  & MTDTechnique.ROOTKIT_SANITIZER        & 1.34\\%     &        1045 \\\\\n",
      " CNC\\_OPT2                & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 0.10\\%     &        1039 \\\\\n",
      " CNC\\_OPT2                & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 0.58\\%     &        1036 \\\\\n",
      " RANSOMWARE\\_POC          & After  & None                                  & 0.00\\%     &         909 \\\\\n",
      " RANSOMWARE\\_POC          & After  & MTDTechnique.CNC_IP_SHUFFLE           & 0.00\\%     &         319 \\\\\n",
      " RANSOMWARE\\_POC          & After  & MTDTechnique.ROOTKIT_SANITIZER        & 0.00\\%     &         852 \\\\\n",
      " RANSOMWARE\\_POC          & After  & MTDTechnique.RANSOMWARE_DIRTRAP       & 89.89\\%    &        1048 \\\\\n",
      " RANSOMWARE\\_POC          & After  & MTDTechnique.RANSOMWARE_FILE_EXT_HIDE & 94.88\\%    &        1036 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "autoencoder.evaluate(n_std=2, tablefmt='latex_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04b21df-6aee-461f-a0c2-314acc997158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "#from src.autoencoder_utils import initial_autoencoder_architecture\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report, accuracy_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "#class AutoEncoder(torch.nn.Module):\n",
    "class AutoEncoder():\n",
    "    \n",
    "    def __init__(self, train_x: np.ndarray,\n",
    "                 valid_x: np.ndarray,\n",
    "                 batch_size: int = 64, batch_size_valid=1):\n",
    "        #super().__init__()\n",
    "            \n",
    "        data_train = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(train_x).type(torch.float),\n",
    "            #torch.from_numpy(train_y).type(torch.float)\n",
    "        )\n",
    "        self.data_loader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "        data_valid = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(valid_x).type(torch.float),\n",
    "            #torch.from_numpy(valid_y).type(torch.float)\n",
    "        )\n",
    "        self.validation_data_loader = torch.utils.data.DataLoader(data_valid, batch_size=batch_size_valid, shuffle=True)\n",
    "        self.validation_losses = []\n",
    "\n",
    "        n_features = train_x.shape[1]\n",
    "        print(f\"n_features: {n_features}\")\n",
    "        self.model = initial_autoencoder_architecture(n_features)\n",
    "        print(self.model)\n",
    "        self.threshold = np.nan\n",
    "        \n",
    "        self.threshold = None\n",
    "        self.loss_mean = None\n",
    "        self.loss_standard_deviation = None\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    def train(self, optimizer=torch.optim.SGD, loss_function=torch.nn.MSELoss(reduction='sum'), num_epochs: int = 15):\n",
    "        epoch_losses = []\n",
    "        # for e in tqdm(range(num_epochs), unit=\"epoch\", leave=False):\n",
    "        for e in range(num_epochs):\n",
    "            self.model.train()\n",
    "            current_losses = []\n",
    "            for batch_idx, (x,) in enumerate(self.data_loader):\n",
    "                x = x  # x.cuda()\n",
    "                optimizer.zero_grad()\n",
    "                model_out = self.model(x)\n",
    "                loss = loss_function(model_out, x)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                current_losses.append(loss.item())\n",
    "            epoch_losses.append(sum(current_losses) / len(current_losses))\n",
    "            # print(f'Training Loss in epoch {e + 1}: {epoch_losses[e]}')\n",
    "        \n",
    "        self.analyze_loss()\n",
    "\n",
    "    '''\n",
    "    This function uses normal data samles \n",
    "    after training the autoencoder to determine\n",
    "    values that can be considered normal\n",
    "    for the reconstruction loss based on normal samples\n",
    "    '''\n",
    "    def analyze_loss(self):\n",
    "        losses = []\n",
    "\n",
    "        self.model.eval() \n",
    "        with torch.no_grad():\n",
    "            loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "            for batch_index, (inputs,) in enumerate(self.validation_data_loader):\n",
    "                outputs = self.forward(inputs)\n",
    "                loss = loss_function(inputs, outputs)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "        losses = np.array(losses)\n",
    "\n",
    "        self.loss_mean = losses.mean()\n",
    "        self.loss_standard_deviation = losses.std()\n",
    "    \n",
    "    '''\n",
    "    def determine_threshold(self, n_std=1) -> float:\n",
    "        mses = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_function = torch.nn.MSELoss(reduction='sum')\n",
    "            for batch_idx, (x,) in enumerate(self.validation_data_loader):\n",
    "                x = x  # x.cuda()\n",
    "                model_out = self.model(x)\n",
    "                loss = loss_function(model_out, x)\n",
    "                mses.append(loss.item())\n",
    "        mses = np.array(mses)\n",
    "        self.loss_mean = mses.mean()\n",
    "        self.loss_standard_deviation = mses.std()\n",
    "        self.threshold = mses.mean() + n_std * mses.std()\n",
    "        return self.threshold\n",
    "    '''\n",
    "\n",
    "    def predict(self, x, n_std=1):\n",
    "        test_data = torch.utils.data.TensorDataset(\n",
    "            torch.from_numpy(x).type(torch.float)\n",
    "        )\n",
    "        data_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "        all_predictions = torch.tensor([])  # .cuda()\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            ae_loss = torch.nn.MSELoss(reduction=\"sum\")\n",
    "            for idx, (batch_x,) in enumerate(data_loader):\n",
    "                batch_x = batch_x  # .cuda()\n",
    "                model_predictions = self.model(batch_x)\n",
    "\n",
    "                model_predictions = ae_loss(model_predictions, batch_x).unsqueeze(0)  # unsqueeze as batch_size set to 1\n",
    "                all_predictions = torch.cat((all_predictions, model_predictions))\n",
    "\n",
    "        threshold = self.loss_mean + n_std * self.loss_standard_deviation\n",
    "        # all_predictions = all_predictions.tolist()\n",
    "        all_predictions = (all_predictions > threshold).type(torch.long)\n",
    "        return all_predictions.flatten()\n",
    "    \n",
    "    def evaluate(self, decision_state_test_data, after_state_test_data, n_std=1, tablefmt='pipe'):\n",
    "        results = []\n",
    "        labels= [0,1]\n",
    "        pos_label = 1\n",
    "        \n",
    "        y_true_total = np.empty([0])\n",
    "        y_pred_total = np.empty([0])\n",
    "        for behavior, data in decision_state_test_data.items():\n",
    "            y_true = np.array([0 if behavior == Behavior.NORMAL else 1] * len(data)).astype(int)\n",
    "            y_true_total = np.concatenate((y_true_total, y_true))\n",
    "\n",
    "            y_pred = self.predict(data[:, :-1].astype(np.float32), n_std=n_std)\n",
    "            y_pred_total = np.concatenate((y_pred_total, y_pred))\n",
    "\n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "            n_samples = len(y_true)\n",
    "            results.append([\"Decisionstate\",\"None\", behavior.name.replace(\"_\", \"\\_\"), f'{(100 * accuracy):.2f}\\%', str(n_samples)])\n",
    "\n",
    "        for (b, m), samples in after_state_test_data.items():\n",
    "            if b == behavior == Behavior.NORMAL or (b, m) in normal_afterstates:\n",
    "                true_label = 0\n",
    "            else:\n",
    "                true_label = 1\n",
    "             \n",
    "            y_true = np.array([true_label] * len(samples)).astype(int) \n",
    "            y_true_total = np.concatenate((y_true_total, y_true))\n",
    "            \n",
    "            y_pred = self.predict(samples[:, :-2].astype(np.float32), n_std=n_std)\n",
    "            y_pred_total = np.concatenate((y_pred_total, y_pred))\n",
    "                \n",
    "            accuracy = accuracy_score(y_true, y_pred)\n",
    "            \n",
    "            n_samples = len(y_true)\n",
    "            results.append([\"Afterstate\", m.name.replace(\"_\", \"\\_\"), b.name.replace(\"_\", \"\\_\"), f'{(100 * accuracy):.2f}\\%', str(n_samples)])\n",
    "            \n",
    "            #print(f\"{b} {m}: {value.shape}\")\n",
    "            \n",
    "        accuracy = accuracy_score(y_true_total, y_pred_total)\n",
    "        precision = precision_score(y_true_total, y_pred_total, average='binary', labels=labels, pos_label=pos_label, zero_division=1)\n",
    "        recall = recall_score(y_true_total, y_pred_total, average='binary', labels=labels, pos_label=pos_label, zero_division=1)\n",
    "        f1 = f1_score(y_true_total, y_pred_total, average='binary', labels=labels, pos_label=pos_label, zero_division=1)\n",
    "        n_samples = len(y_true_total)\n",
    "        results.append([\"\", \"\", \"GLOBAL\", f'{(100 * accuracy):.2f}\\%', n_samples])\n",
    "        print(\"-----------\")\n",
    "        print(tabulate(results, headers=[\"State\", \"After MTD\", \"Behavior\", \"Accuracy\", \"\\#Samples\"], tablefmt=tablefmt))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f475c629-8a5a-43b5-bf66-40983433ca48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretrain_ae_model(ae_data, split=0.8, lr=1e-4, momentum=0.9, num_epochs=100, n_std=2.5):\n",
    "    idx = int(len(ae_data) * split)\n",
    "    train_ae_x = ae_data[:idx,:].astype(np.float32)\n",
    "    valid_ae_x = ae_data[idx:,:].astype(np.float32)\n",
    "    print(f\"size train: {train_ae_x.shape}, size valid: {valid_ae_x.shape}\")\n",
    "\n",
    "    print(\"---Training AE---\")\n",
    "    autoencoder = AutoEncoder(train_x=train_ae_x, valid_x=valid_ae_x)\n",
    "    autoencoder.train(optimizer=torch.optim.Adam(autoencoder.model.parameters(), lr=lr,  weight_decay=0.01), num_epochs=num_epochs)\n",
    "    return autoencoder, train_ae_x, valid_ae_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5934ed0-b85e-4e8a-b125-835c5a4c546e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pretrain_autoencoder(decision_states_data, ae_train_dict, dir=\"experiments/experiment_03/trained_models\", n_std=1):\n",
    "    #for key, value in ae_train_dict.items():\n",
    "    #    print(f\"{key}:{len(value)}\")\n",
    "    #\"\"\"pretrains autoencoder models on 1. decision state normal,\n",
    "    #2. on each normal-mtd combination,\n",
    "    #3. on both decision and normal-mtd combination data\"\"\"\n",
    "    #ae, all_train, all_valid = pretrain_ae_model(decision_states_data)\n",
    "    #for i, mtd in enumerate(ae_train_dict):\n",
    "    #    path = f\"{dir}/ae_model_{mtd.value}.pth\"\n",
    "    #    ae, train_data, valid_data = pretrain_ae_model(ae_train_dict[mtd][:, :-1], n_std=n_std)\n",
    "    #    all_train = np.vstack((all_train, train_data))\n",
    "    #    all_valid = np.vstack((all_valid, valid_data))\n",
    "    #    # for all afterstate model\n",
    "    #    if i == 0:\n",
    "    #        all_as_train, all_as_valid = train_data, valid_data\n",
    "    #    else:\n",
    "    #        all_as_train = np.vstack((all_as_train, train_data))\n",
    "    #        all_as_valid = np.vstack((all_as_valid, valid_data))\n",
    "    #\n",
    "    #all_as_data = np.vstack((all_as_train, all_as_valid))\n",
    "    #all_as_data = np.hstack((all_as_data, np.ones((len(all_as_data), 1))))\n",
    "    #print(\"all as data: \", len(all_as_data))\n",
    "    #pretrain_ae_model(all_as_data, n_std=n_std, num_epochs=100, lr=1e-4)\n",
    "\n",
    "    #all_data = np.vstack((all_train, all_valid))\n",
    "    #all_data = np.hstack((all_data, np.ones((len(all_data), 1))))\n",
    "    #print(\"all ds/as data: \", len(all_data))\n",
    "    #print(f\"all_data(type): {type(all_data)}\")\n",
    "    decision_states_data_x = decision_states_data[:,:-1]\n",
    "    n_features = decision_states_data_x.shape[1]\n",
    "    combined_training_data = np.empty([0, n_features])\n",
    "    for key, value in ae_train_dict.items():\n",
    "        combined_training_data = np.vstack([combined_training_data, value[:,:-2]])\n",
    "    return pretrain_ae_model(combined_training_data, n_std=n_std, num_epochs=100, lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c1d802c-9ccc-4029-b8c0-9e66f1656f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_as_data_for_ae_and_rl(train_data, s=0.3):\n",
    "    ae_dict = {}\n",
    "    for mtd in MTDTechnique:\n",
    "        normal_mtd_train = train_data[(Behavior.NORMAL, mtd)]\n",
    "        train_data[(Behavior.NORMAL, mtd)] = normal_mtd_train[:int(s * len(normal_mtd_train))]\n",
    "        ae_dict[mtd] = normal_mtd_train[int(s * len(normal_mtd_train)):]\n",
    "    return ae_dict, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe8447eb-f74b-41eb-9751-4aac622b0054",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting Behavior.NORMAL\n",
      "getting Behavior.RANSOMWARE_POC\n",
      "getting Behavior.ROOTKIT_BDVL\n",
      "getting Behavior.CNC_BACKDOOR_JAKORITAR\n",
      "getting Behavior.ROOTKIT_BEURK\n",
      "getting Behavior.CNC_THETICK\n",
      "getting Behavior.CNC_OPT1\n",
      "getting Behavior.CNC_OPT2\n",
      "(16924, 87)\n",
      "(60197, 88)\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(None, -1, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), slice(None, -1, None))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read in all preprocessed data for a simulated, supervised environment to sample from\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# dtrain, dtest, atrain, atest = DataProvider.get_reduced_dimensions_with_pca_ds_as(DIMS,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#                                                                                   dir=f\"{experiment_base_dir}/\")\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m decision_states_training_data_dict, decision_states_test_data_dict, after_states_training_data_dict, after_states_test_data_dict, scaler \u001b[38;5;241m=\u001b[39m \u001b[43mDataProvider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_scaled_scaled_train_test_split_with_afterstates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_minmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_normal_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# get splits for RL & AD of normal data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ae_decision_states_training_data, rl_decision_states_training_data_dict \u001b[38;5;241m=\u001b[39m DataProvider\u001b[38;5;241m.\u001b[39msplit_ds_data_for_ae_and_rl(decision_states_training_data_dict)\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/Master-Thesis/Code/src/data_provider.py:279\u001b[0m, in \u001b[0;36mDataProvider.get_scaled_scaled_train_test_split_with_afterstates\u001b[0;34m(split, scaling_minmax, scale_normal_only)\u001b[0m\n\u001b[1;32m    277\u001b[0m test_adata[(b, mtd)] \u001b[38;5;241m=\u001b[39m a_test\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m scale_normal_only \u001b[38;5;129;01mand\u001b[39;00m b \u001b[38;5;241m==\u001b[39m Behavior\u001b[38;5;241m.\u001b[39mNORMAL:\n\u001b[0;32m--> 279\u001b[0m     train_filtered \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((train_filtered, \u001b[43matrain_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scale_normal_only:\n\u001b[1;32m    282\u001b[0m     train_filtered \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack((train_filtered, atrain_filtered[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/pandas/core/indexes/base.py:3810\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3810\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/FedRL-for-IT-Sec/lib/python3.10/site-packages/pandas/core/indexes/base.py:5968\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5966\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5967\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5968\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(None, -1, None))"
     ]
    }
   ],
   "source": [
    "# read in all preprocessed data for a simulated, supervised environment to sample from\n",
    "# dtrain, dtest, atrain, atest = DataProvider.get_reduced_dimensions_with_pca_ds_as(DIMS,\n",
    "#                                                                                   dir=f\"{experiment_base_dir}/\")\n",
    "decision_states_training_data_dict, decision_states_test_data_dict, after_states_training_data_dict, after_states_test_data_dict, scaler = DataProvider.get_scaled_scaled_train_test_split_with_afterstates(\n",
    "    scaling_minmax=True, scale_normal_only=True)\n",
    "\n",
    "# get splits for RL & AD of normal data\n",
    "ae_decision_states_training_data, rl_decision_states_training_data_dict = DataProvider.split_ds_data_for_ae_and_rl(decision_states_training_data_dict)\n",
    "ae_decision_states_training_data = np.vstack((ae_decision_states_training_data, ae_decision_states_training_data)) # upsampling to have equal contribution with afterstates\n",
    "dims = len(ae_decision_states_training_data[0, :-1])\n",
    "ae_after_states_training_data_dict, rl_after_states_training_data_dict = DataProvider.split_as_data_for_ae_and_rl(after_states_training_data_dict)\n",
    "\n",
    "#print(f\"dtrain.shape: {len(dtrain)}; dtrain.type: {type(dtrain)}\")\n",
    "#print(f\"dtest.shape: {len(dtest)}; dtest.type: {type(dtest)}\")\n",
    "#print(f\"atrain.shape: {len(atrain)}; atrain.type: {type(atrain)}\")\n",
    "#print(f\"atest.shape: {len(atest)}; atest.type: {type(atest)}\")\n",
    "#print(\"---\")\n",
    "#print(f\"ae_ds_train.shape: {len(ae_ds_train)}; ae_ds_train.type: {type(ae_ds_train)}\")\n",
    "#print(f\"dtrain_rl .shape: {len(dtrain_rl)}; dtrain_rl .type: {type(dtrain_rl)}\")\n",
    "#print(f\"ae_as_train.shape: {len(ae_as_train)}; ae_as_train.type: {type(ae_as_train)}\")\n",
    "#print(f\"atrain_rl.shape: {len(atrain_rl)}; atrain_rl.type: {type(atrain_rl)}\")\n",
    "\n",
    "# MODEL trained on all ds and as normal data assumes the least -> MOST REALISTIC\n",
    "#autoencoder = pretrain_autoencoder(ae_ds_train, ae_as_train, n_std=2.5)\n",
    "#evaluate_all_ds_as_ae_models(autoencoder, dtrain_rl, atrain_rl, dims=dims, dir=dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f11b65e9-6f67-4a5d-b822-2907094be942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2716, 87)\n"
     ]
    }
   ],
   "source": [
    "print(ae_decision_states_training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41354797-1cc0-4ba8-8617-945b96477aff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior.NORMAL: (825, 87)\n",
      "Behavior.RANSOMWARE_POC: (351, 87)\n",
      "Behavior.ROOTKIT_BDVL: (321, 87)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR: (393, 87)\n",
      "Behavior.ROOTKIT_BEURK: (392, 87)\n",
      "Behavior.CNC_THETICK: (291, 87)\n",
      "Behavior.CNC_OPT1: (406, 87)\n",
      "Behavior.CNC_OPT2: (405, 87)\n",
      "3384\n"
     ]
    }
   ],
   "source": [
    "# 86 features\n",
    "n_total = 0\n",
    "for key, value in decision_states_test_data_dict.items():\n",
    "    n_total+=value.shape[0]\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "print(n_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64fb9e92-e811-4a6b-900e-e3a9776980fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior.NORMAL: (582, 87)\n",
      "Behavior.RANSOMWARE_POC: (905, 87)\n",
      "Behavior.ROOTKIT_BDVL: (799, 87)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR: (1025, 87)\n",
      "Behavior.ROOTKIT_BEURK: (951, 87)\n",
      "Behavior.CNC_THETICK: (730, 87)\n",
      "Behavior.CNC_OPT1: (1061, 87)\n",
      "Behavior.CNC_OPT2: (1075, 87)\n",
      "7128\n"
     ]
    }
   ],
   "source": [
    "# 86 features\n",
    "n_total = 0\n",
    "for key, value in decision_states_training_data_dict.items():\n",
    "    n_total+=value.shape[0]\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "print(n_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d15df1-c582-4496-a570-946b1726e228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior.NORMAL: (582, 87)\n",
      "Behavior.RANSOMWARE_POC: (905, 87)\n",
      "Behavior.ROOTKIT_BDVL: (799, 87)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR: (1025, 87)\n",
      "Behavior.ROOTKIT_BEURK: (951, 87)\n",
      "Behavior.CNC_THETICK: (730, 87)\n",
      "Behavior.CNC_OPT1: (1061, 87)\n",
      "Behavior.CNC_OPT2: (1075, 87)\n",
      "7128\n"
     ]
    }
   ],
   "source": [
    "# 86 features\n",
    "n_total = 0\n",
    "for key, value in rl_decision_states_training_data_dict.items():\n",
    "    n_total+=value.shape[0]\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "print(n_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51a1ffac-8189-49cf-b5ea-54e4dcb497f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior.NORMAL: (581, 87)\n",
      "Behavior.RANSOMWARE_POC: (921, 87)\n",
      "Behavior.ROOTKIT_BDVL: (802, 87)\n",
      "Behavior.CNC_BACKDOOR_JAKORITAR: (1014, 87)\n",
      "Behavior.ROOTKIT_BEURK: (929, 87)\n",
      "Behavior.CNC_THETICK: (716, 87)\n",
      "Behavior.CNC_OPT1: (1067, 87)\n",
      "Behavior.CNC_OPT2: (1075, 87)\n"
     ]
    }
   ],
   "source": [
    "for key, value in rl_decision_states_training_data_dict.items():\n",
    "    print(f\"{key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16d7e05-cee1-4ffb-a22b-dac605cbb487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key, value in rl_after_states_training_data_dict.items():\n",
    "    print(f\"{key}: {value[:,-2:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49c83077-773c-4932-8d8d-60b7ec3d0047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2716, 87)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(ae_decision_states_training_data.shape)\n",
    "print(len(ae_after_states_training_data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6278735-988b-440d-a6ae-e5c61413be85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size train: (2256, 86), size valid: (565, 86)\n",
      "---Training AE---\n",
      "n_features: 86\n",
      "Sequential(\n",
      "  (0): Linear(in_features=86, out_features=64, bias=True)\n",
      "  (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): GELU(approximate='none')\n",
      "  (3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (4): GELU(approximate='none')\n",
      "  (5): Linear(in_features=32, out_features=16, bias=True)\n",
      "  (6): GELU(approximate='none')\n",
      "  (7): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (8): GELU(approximate='none')\n",
      "  (9): Linear(in_features=8, out_features=16, bias=True)\n",
      "  (10): GELU(approximate='none')\n",
      "  (11): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (12): GELU(approximate='none')\n",
      "  (13): Linear(in_features=32, out_features=64, bias=True)\n",
      "  (14): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (15): GELU(approximate='none')\n",
      "  (16): Linear(in_features=64, out_features=86, bias=True)\n",
      "  (17): GELU(approximate='none')\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "autoencoder, _, _ = pretrain_autoencoder(ae_decision_states_training_data, ae_after_states_training_data_dict, n_std=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "805bb902-7f96-4798-852d-e1e869b69f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------\n",
      "| State         | After MTD                   | Behavior                 | Accuracy   |   \\#Samples |\n",
      "|:--------------|:----------------------------|:-------------------------|:-----------|------------:|\n",
      "| Decisionstate | None                        | NORMAL                   | 99.14\\%    |         582 |\n",
      "| Decisionstate | None                        | RANSOMWARE\\_POC          | 100.00\\%   |         905 |\n",
      "| Decisionstate | None                        | ROOTKIT\\_BDVL            | 100.00\\%   |         799 |\n",
      "| Decisionstate | None                        | CNC\\_BACKDOOR\\_JAKORITAR | 40.68\\%    |        1025 |\n",
      "| Decisionstate | None                        | ROOTKIT\\_BEURK           | 1.16\\%     |         951 |\n",
      "| Decisionstate | None                        | CNC\\_THETICK             | 100.00\\%   |         730 |\n",
      "| Decisionstate | None                        | CNC\\_OPT1                | 99.81\\%    |        1061 |\n",
      "| Decisionstate | None                        | CNC\\_OPT2                | 100.00\\%   |        1075 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | NORMAL                   | 0.32\\%     |         317 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | NORMAL                   | 3.34\\%     |         299 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | NORMAL                   | 3.90\\%     |         282 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | NORMAL                   | 2.91\\%     |         309 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | RANSOMWARE\\_POC          | 97.00\\%    |         968 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | RANSOMWARE\\_POC          | 97.70\\%    |         955 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | RANSOMWARE\\_POC          | 100.00\\%   |         344 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | RANSOMWARE\\_POC          | 100.00\\%   |        1029 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | ROOTKIT\\_BDVL            | 100.00\\%   |         725 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | ROOTKIT\\_BDVL            | 100.00\\%   |         368 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | ROOTKIT\\_BDVL            | 100.00\\%   |         360 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | ROOTKIT\\_BDVL            | 2.90\\%     |        1139 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | CNC\\_BACKDOOR\\_JAKORITAR | 33.47\\%    |         947 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | CNC\\_BACKDOOR\\_JAKORITAR | 100.00\\%   |        1106 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | CNC\\_BACKDOOR\\_JAKORITAR | 61.64\\%    |        1014 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | CNC\\_BACKDOOR\\_JAKORITAR | 22.76\\%    |        1028 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | ROOTKIT\\_BEURK           | 2.70\\%     |         925 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | ROOTKIT\\_BEURK           | 3.59\\%     |         976 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | ROOTKIT\\_BEURK           | 2.27\\%     |         968 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | ROOTKIT\\_BEURK           | 97.97\\%    |         984 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | CNC\\_THETICK             | 38.30\\%    |        1000 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | CNC\\_THETICK             | 12.59\\%    |        1080 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | CNC\\_THETICK             | 77.95\\%    |        1161 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | CNC\\_THETICK             | 5.46\\%     |         970 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | CNC\\_OPT1                | 99.31\\%    |        1018 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | CNC\\_OPT1                | 99.41\\%    |        1021 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | CNC\\_OPT1                | 92.51\\%    |        1229 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | CNC\\_OPT1                | 99.24\\%    |         919 |\n",
      "| Afterstate    | RANSOMWARE\\_DIRTRAP         | CNC\\_OPT2                | 100.00\\%   |        1222 |\n",
      "| Afterstate    | RANSOMWARE\\_FILE\\_EXT\\_HIDE | CNC\\_OPT2                | 100.00\\%   |        1145 |\n",
      "| Afterstate    | CNC\\_IP\\_SHUFFLE            | CNC\\_OPT2                | 85.68\\%    |        1131 |\n",
      "| Afterstate    | ROOTKIT\\_SANITIZER          | CNC\\_OPT2                | 100.00\\%   |        1091 |\n",
      "|               |                             | GLOBAL                   | 67.25\\%    |       35158 |\n"
     ]
    }
   ],
   "source": [
    "autoencoder.evaluate(rl_decision_states_training_data_dict, rl_after_states_training_data_dict, n_std=3, tablefmt='pipe')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "FedRL-for-IT-Sec",
   "language": "python",
   "name": "fedrl-for-it-sec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
